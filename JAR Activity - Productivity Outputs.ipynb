{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c2c1a4-17ad-45b1-92a5-088723e56228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Operational JAR Logic, applied to PAT Intermediate Table - South West\n",
    "## NHS England South West Intelligence and Insights\n",
    " \n",
    "The **Southwest Elective Delivery Dashboard** provides a summary of elective waiting lists and activity recovery. This script focuses on the elective aspect of the dashboard, tracking recovery progress against both planned targets and the 2023/24 baseline where applicable. It integrates the latest publicly available monthly data, broken down by week, and appends the most recent unpublished weekly data to ensure reporting is up to date with the latest available figures.\n",
    "\n",
    "### Scripts\n",
    " \n",
    "#### Provider Focus\n",
    "üìù National JAR methodology - Accident and Emergency Attendance - Provider - PAT  \n",
    "üìù National JAR methodology - Admitted patient care script - Provider - PAT   \n",
    "üìù National JAR methodology - Outpatient Attendance script - Provider - PAT   \n",
    "\n",
    "### About the Scripts\n",
    "The PAT and FasterSUS scripts are ran using National Planning logic, the below applies to both APC and OP scripts:  \n",
    "- Acute Provider Only  \n",
    "- Consultant led Specific Acute activity only  \n",
    "- Treatment Function Code 360 and 812 (op) is excluded  \n",
    "- Excluding Private patients\n",
    " \n",
    "üöë **Accident and Emergency Attendance script**  \n",
    "*This script covers Emergency Care attendances, sourced from the National PAT Intermediate EC SUS table*  \n",
    "\n",
    "üè• **Admitted patient care script**  \n",
    "*This script covers both elective and non-elective hospital activity, sourced from the National PAT Intermediate Admitted Patient Care SUS table*  \n",
    "\n",
    "üë®‚Äç‚öïÔ∏è **Outpatient Attendance script**  \n",
    "*This script covers Outpatient attendances, sourced from the National PAT Intermediate OP SUS table*  \n",
    "\n",
    "### Built With SQL and Python in DataBricks\n",
    " \n",
    "üõ¢Ô∏è[DataBricks](About Databricks: The data and AI company | Databricks)  \n",
    "üõ¢Ô∏è[UDAL](https://rdweb.wvd.microsoft.com) \n",
    "\n",
    "#### Datasets in the lakemart on DataBricks\n",
    "üõ¢Ô∏è Pat_intermediate_OPA \n",
    "üõ¢Ô∏è Pat_intermediate_APC \n",
    "üõ¢Ô∏è Pat_intermediate_AE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51423f3f-7b58-4fb3-9b37-c6438cfb2c56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Load the Tables  \n",
    "\n",
    "Before we dive into the data, we need to **load the necessary tables** into the **Hive Metastore**.  \n",
    "\n",
    "#### Why is this needed?  \n",
    "Right now, the data does not exist in the **Lakemart**, until it's been included, we use this **temporary workaround**. Thanks to the **National Elective Team**, we have access to their **ERIC workspace** to make this possible.  \n",
    "\n",
    "#### Best Practice  \n",
    "Since these tables **refresh daily**, it's always best to **drop and reload** them to ensure you're working with the most up-to-date data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a23cbef5-0569-4dab-b7cb-dadff32ac50c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "--Load neccassary reference tables\n",
    "drop table if exists eric.Provider_Hierarchies_DB;\n",
    "create table eric.Provider_Hierarchies_DB\n",
    "using parquet\n",
    "location \"abfss://reporting@udalstdatacuratedprod.dfs.core.windows.net/unrestricted/reference/UKHD/ODS/Provider_Hierarchies/\";\n",
    "\n",
    "drop table if exists eric.Date_Full_DB;\n",
    "create table eric.Date_Full_DB\n",
    "using parquet\n",
    "location \"abfss://unrestricted@udalstdatacuratedprod.dfs.core.windows.net/reference/Internal/Reference/Date_Full/Published/1/\";\n",
    "\n",
    "drop table if exists eric.TreatmentFunctionCodes_DB;\n",
    "create table eric.TreatmentFunctionCodes_DB\n",
    "using parquet\n",
    "location \"abfss://unrestricted@udalstdatacuratedprod.dfs.core.windows.net/aggregated/UKHF/Treatment_Function/Codes1/\"\n",
    "options(recursiveFileLookup=true);\n",
    "\n",
    "--Load neccassary PAT Intermediate tables\n",
    "\n",
    "drop table if exists eric.PAT_Intermediate_Table_APC_DB;\n",
    "create table eric.PAT_Intermediate_Table_APC_DB\n",
    "using parquet\n",
    "location \"abfss://restricted@udalstdatacuratedprod.dfs.core.windows.net/patientlevel/UDALSQLMART/PatActivity/PAT_Intermediate_Table_APC/\"\n",
    "options(recursiveFileLookup=true);\n",
    "\n",
    "drop table if exists eric.PAT_Intermediate_Table_OP_DB;\n",
    "create table eric.PAT_Intermediate_Table_OP_DB\n",
    "using parquet\n",
    "location \"abfss://restricted@udalstdatacuratedprod.dfs.core.windows.net/patientlevel/UDALSQLMART/PatActivity/PAT_Intermediate_Table_OP/\"\n",
    "options(recursiveFileLookup=true);\n",
    "\n",
    "drop table if exists eric.PAT_Intermediate_Table_AE_DB;\n",
    "create table eric.PAT_Intermediate_Table_AE_DB\n",
    "using parquet\n",
    "location \"abfss://restricted@udalstdatacuratedprod.dfs.core.windows.net/patientlevel/UDALSQLMART/PatActivity/PAT_Intermediate_Table_AE/\"\n",
    "options(recursiveFileLookup=true);\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07ce321c-7b11-4d09-9caf-0a771fc914c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Create the Views  \n",
    "\n",
    "There are three views using SQL Spark version of the legacy SQL view initialy created in NCDR and the replicated in UDAL, for APC, OP and AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba1b4756-6b70-46f0-84f7-ffc4e97b7646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CREATE OR REPLACE TEMPORARY VIEW PAT_APC AS\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN susapc.Provider_Current IN ('RD3', 'RDZ') THEN 'R0D'\n",
    "        WHEN susapc.Provider_Current = 'RBZ' THEN 'RH8'\n",
    "        WHEN susapc.Provider_Current = 'RA3' THEN 'RA7'\n",
    "        WHEN susapc.Provider_Current = 'RBA' THEN 'RH5'\n",
    "        WHEN susapc.Provider_Current = 'R1G' THEN 'RA9'\n",
    "        WHEN susapc.Provider_Current = 'RVJ13' THEN 'RVJ'\n",
    "        WHEN susapc.Provider_Current = 'RA4' THEN 'RH5'\n",
    "        ELSE susapc.Provider_Current\n",
    "    END AS Provider_Code,\n",
    " \n",
    "    CASE\n",
    "        WHEN o.organisation_name = 'ROYAL DEVON AND EXETER NHS FOUNDATION TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TAUNTON AND SOMERSET NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'NORTHERN DEVON HEALTHCARE NHS TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name IN (\n",
    "            'THE ROYAL BOURNEMOUTH AND CHRISTCHURCH HOSPITALS NHS FOUNDATION TRUST',\n",
    "            'POOLE HOSPITAL NHS FOUNDATION TRUST'\n",
    "        ) THEN 'UNIVERSITY HOSPITAL DORSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TORBAY AND SOUTHERN DEVON HEALTH AND CARE NHS TRUST' THEN 'TORBAY AND SOUTH DEVON NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'EMERSONS GREEN NHS TREATMENT CENTRE' THEN 'NORTH BRISTOL NHS TRUST'\n",
    "        WHEN o.organisation_name = 'YEOVIL DISTRICT HOSPITAL NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'  \n",
    "        WHEN o.organisation_name = 'UNIVERSITY HOSPITALS BRISTOL NHS FOUNDATION TRUST' THEN 'UNIVERSITY HOSPITALS BRISTOL AND WESTON NHS FOUNDATION TRUST'\n",
    "        ELSE o.organisation_name  \n",
    "    END AS organisation_name,\n",
    " \n",
    "    o.STP_Code,\n",
    "    o.STP_Name,\n",
    "    right(susapc.Dimention_3, 3) AS TFC,\n",
    "    T.Treatment_Function_Title,\n",
    "    LEFT(susapc.Dimention_7, 5) AS HRG,\n",
    "    susapc.Pat_Commissioner_Type,\n",
    "    CONCAT(YEAR(susapc.Discharge_Date), LPAD(MONTH(susapc.Discharge_Date),2,'0')) AS YearMonth,\n",
    " \n",
    "    susapc.LOS_unadjusted,\n",
    " \n",
    "    CASE \n",
    "        WHEN susapc.Der_Management_Type = 'EM' THEN 'NE' \n",
    "        ELSE susapc.Der_Management_Type \n",
    "    END AS Der_Management_Type,\n",
    " \n",
    "    CASE \n",
    "        WHEN susapc.Dimention_5 = 'A: 0 day LOS' THEN '0 Day LOS' \n",
    "        ELSE '1+ Day LOS' \n",
    "    END AS LOS,\n",
    " \n",
    "    susapc.Discharge_Date,\n",
    " \n",
    "    COUNT(susapc.unadjusted) AS Total_Activty_Unadj,\n",
    "    COUNT(susapc.adjusted) AS Total_Activty_Adj\n",
    " \n",
    "FROM eric.PAT_Intermediate_Table_APC_DB AS susapc\n",
    " \n",
    "LEFT JOIN eric.Provider_Hierarchies_DB o \n",
    "    ON susapc.Provider_Current = o.Organisation_Code  \n",
    " \n",
    "LEFT JOIN eric.Date_Full_DB AS d \n",
    "    ON d.Full_Date = susapc.Discharge_Date\n",
    " \n",
    "LEFT JOIN eric.TreatmentFunctionCodes_DB AS T \n",
    "    ON Right(susapc.Dimention_3, 3) = T.DD_Code\n",
    " \n",
    "WHERE\n",
    "    susapc.Discharge_Date >= '2024-04-01'\n",
    "    AND susapc.Der_Management_Type IN ('EL', 'DC', 'EM', 'NE')\n",
    "    AND susapc.Provider_Current IN (\n",
    "        'RD1', 'RN3', 'RNZ', 'RA7', 'RVJ', 'REF', 'RA9', 'RH8',\n",
    "        'RK9', 'RBD', 'R0D', 'RTE', 'RH5'\n",
    "    )\n",
    "\n",
    "and susapc.Dimention_4 = 'Specific Acute'\n",
    "\n",
    " --   AND right(susapc.Dimention_3, 3) NOT IN (\n",
    " --       '199', '223', '290', '291', '331', '344', '345', '346', '360',\n",
    " --       '424', '499', '501', '504', '560', '650', '651', '652', '653',\n",
    " --       '654', '655', '656', '657', '658', '659', '660', '661', '662',\n",
    " --       '700', '710', '711', '712', '713', '715', '720', '721', '722',\n",
    " --       '723', '724', '725', '726', '727', '730', '840', '920','NULL'\n",
    " --   )\n",
    " \n",
    "    AND susapc.Pat_Commissioner_Type <> 'Private Patient'\n",
    " \n",
    "GROUP BY\n",
    "    susapc.Provider_Current,\n",
    "    o.organisation_name,\n",
    "    o.STP_Code,\n",
    "    o.STP_Name,\n",
    "    right(susapc.Dimention_3,3),\n",
    "    T.Treatment_Function_Title,\n",
    "    LEFT(susapc.Dimention_7,5),\n",
    "    susapc.Pat_Commissioner_Type,\n",
    "    susapc.Discharge_Date,\n",
    "    susapc.LOS_unadjusted,\n",
    "    susapc.Der_Management_Type,\n",
    "    susapc.Dimention_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6565eb17-1b34-4c67-a6d2-78becac8d2be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CREATE OR REPLACE TEMPORARY VIEW PAT_OP AS\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN susop.Provider_Current IN ('RD3', 'RDZ') THEN 'R0D'\n",
    "        WHEN susop.Provider_Current = 'RBZ' THEN 'RH8'\n",
    "        WHEN susop.Provider_Current = 'RA3' THEN 'RA7'\n",
    "        WHEN susop.Provider_Current = 'RBA' THEN 'RH5'\n",
    "        WHEN susop.Provider_Current = 'R1G' THEN 'RA9'\n",
    "        WHEN susop.Provider_Current = 'RVJ13' THEN 'RVJ'\n",
    "        WHEN susop.Provider_Current = 'RA4' THEN 'RH5'\n",
    "        ELSE susop.Provider_Current\n",
    "    END AS Provider_Code,\n",
    " \n",
    "    CASE\n",
    "        WHEN o.organisation_name = 'ROYAL DEVON AND EXETER NHS FOUNDATION TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TAUNTON AND SOMERSET NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'NORTHERN DEVON HEALTHCARE NHS TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name IN (\n",
    "            'THE ROYAL BOURNEMOUTH AND CHRISTCHURCH HOSPITALS NHS FOUNDATION TRUST',\n",
    "            'POOLE HOSPITAL NHS FOUNDATION TRUST'\n",
    "        ) THEN 'UNIVERSITY HOSPITAL DORSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TORBAY AND SOUTHERN DEVON HEALTH AND CARE NHS TRUST' THEN 'TORBAY AND SOUTH DEVON NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'EMERSONS GREEN NHS TREATMENT CENTRE' THEN 'NORTH BRISTOL NHS TRUST'\n",
    "        WHEN o.organisation_name = 'YEOVIL DISTRICT HOSPITAL NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'  \n",
    "        WHEN o.organisation_name = 'UNIVERSITY HOSPITALS BRISTOL NHS FOUNDATION TRUST' THEN 'UNIVERSITY HOSPITALS BRISTOL AND WESTON NHS FOUNDATION TRUST'\n",
    "        ELSE o.organisation_name  \n",
    "    END AS organisation_name,\n",
    " \n",
    "    o.STP_Code,\n",
    "    o.STP_Name,\n",
    "    right(susop.Dimention_3, 3) AS TFC,\n",
    "    T.Treatment_Function_Title,\n",
    "    LEFT(susop.Dimention_7, 5) AS HRG,\n",
    "    susop.Pat_Commissioner_Type,\n",
    "    CONCAT(YEAR(susop.Attendance_Date), LPAD(MONTH(susop.Attendance_Date),2,'0')) AS YearMonth,\n",
    "    \n",
    "    CASE \n",
    "        WHEN susop.Dimention_1 LIKE 'Follow%' THEN 'Outpatient Follow-Up'\n",
    "        WHEN susop.Dimention_1 LIKE '1st%' THEN 'Outpatient First Appointment'\n",
    "        ELSE susop.Dimention_1 \n",
    "    END AS High_Level_Pod,\n",
    " \n",
    "    susop.Attendance_Date,\n",
    " \n",
    "    COUNT(susop.unadjusted) AS Total_Activty_Unadj,\n",
    "    COUNT(susop.adjusted) AS Total_Activty_Adj\n",
    " \n",
    "FROM eric.PAT_Intermediate_Table_OP_DB AS susop\n",
    " \n",
    "LEFT JOIN eric.Provider_Hierarchies_DB o \n",
    "    ON susop.Provider_Current = o.Organisation_Code  \n",
    " \n",
    "LEFT JOIN eric.Date_Full_DB AS d \n",
    "    ON d.Full_Date = susop.Attendance_Date\n",
    " \n",
    "LEFT JOIN eric.TreatmentFunctionCodes_DB AS T \n",
    "    ON right(susop.Dimention_3, 3) = T.DD_Code\n",
    " \n",
    "WHERE\n",
    "    susop.Attendance_Date >= '2024-04-01'\n",
    "\n",
    "    AND susop.Provider_Current IN (\n",
    "        'RD1', 'RN3', 'RNZ', 'RA7', 'RVJ', 'REF', 'RA9', 'RH8',\n",
    "        'RK9', 'RBD', 'R0D', 'RTE', 'RH5'\n",
    "    )\n",
    "\n",
    "and susop.Dimention_4 = 'Consultant led: Specific Acute'\n",
    "\n",
    "and susop.Dimention_1 <> 'Unknown Appointment Type'\n",
    "\n",
    " --   AND right(susapc.Dimention_3, 3) NOT IN (\n",
    " --       '199', '223', '290', '291', '331', '344', '345', '346', '360',\n",
    " --       '424', '499', '501', '504', '560', '650', '651', '652', '653',\n",
    " --       '654', '655', '656', '657', '658', '659', '660', '661', '662',\n",
    " --       '700', '710', '711', '712', '713', '715', '720', '721', '722',\n",
    " --       '723', '724', '725', '726', '727', '730', '840', '920','NULL'\n",
    " --   )\n",
    " \n",
    "    AND susop.Pat_Commissioner_Type <> 'Private Patient'\n",
    " \n",
    "GROUP BY\n",
    "susop.Provider_Current,\n",
    "o.organisation_name,\n",
    "o.STP_Code,\n",
    "o.STP_Name,\n",
    "right(susop.Dimention_3, 3),\n",
    "T.Treatment_Function_Title,\n",
    "LEFT(susop.Dimention_7, 5),\n",
    "susop.Pat_Commissioner_Type,\n",
    "Attendance_Date,\n",
    "Dimention_1,\n",
    "susop.Attendance_Date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f29c700c-54d4-4830-8001-3bb7fa1a434e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CREATE OR REPLACE TEMPORARY VIEW PAT_AE AS\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN susae.Provider_Current IN ('RD3', 'RDZ') THEN 'R0D'\n",
    "        WHEN susae.Provider_Current = 'RBZ' THEN 'RH8'\n",
    "        WHEN susae.Provider_Current = 'RA3' THEN 'RA7'\n",
    "        WHEN susae.Provider_Current = 'RBA' THEN 'RH5'\n",
    "        WHEN susae.Provider_Current = 'R1G' THEN 'RA9'\n",
    "        WHEN susae.Provider_Current = 'RVJ13' THEN 'RVJ'\n",
    "        WHEN susae.Provider_Current = 'RA4' THEN 'RH5'\n",
    "        ELSE susae.Provider_Current\n",
    "    END AS Provider_Code,\n",
    " \n",
    "    CASE\n",
    "        WHEN o.organisation_name = 'ROYAL DEVON AND EXETER NHS FOUNDATION TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TAUNTON AND SOMERSET NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'NORTHERN DEVON HEALTHCARE NHS TRUST' THEN 'ROYAL DEVON UNIVERSITY HEALTHCARE NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name IN (\n",
    "            'THE ROYAL BOURNEMOUTH AND CHRISTCHURCH HOSPITALS NHS FOUNDATION TRUST',\n",
    "            'POOLE HOSPITAL NHS FOUNDATION TRUST'\n",
    "        ) THEN 'UNIVERSITY HOSPITAL DORSET NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'TORBAY AND SOUTHERN DEVON HEALTH AND CARE NHS TRUST' THEN 'TORBAY AND SOUTH DEVON NHS FOUNDATION TRUST'\n",
    "        WHEN o.organisation_name = 'EMERSONS GREEN NHS TREATMENT CENTRE' THEN 'NORTH BRISTOL NHS TRUST'\n",
    "        WHEN o.organisation_name = 'YEOVIL DISTRICT HOSPITAL NHS FOUNDATION TRUST' THEN 'SOMERSET NHS FOUNDATION TRUST'  \n",
    "        WHEN o.organisation_name = 'UNIVERSITY HOSPITALS BRISTOL NHS FOUNDATION TRUST' THEN 'UNIVERSITY HOSPITALS BRISTOL AND WESTON NHS FOUNDATION TRUST'\n",
    "        ELSE o.organisation_name  \n",
    "    END AS organisation_name,\n",
    " \n",
    "    o.STP_Code,\n",
    "    o.STP_Name,\n",
    "    LEFT(susae.Dimention_7, 5) AS HRG,\n",
    "    susae.Pat_Commissioner_Type,\n",
    "    CONCAT(YEAR(susae.Attendance_Date), LPAD(MONTH(susae.Attendance_Date),2,'0')) AS YearMonth,\n",
    "    \n",
    "    susae.Dimention_1 AS Metric_ID,\n",
    " \n",
    "    susae.Attendance_Date,\n",
    " \n",
    "    COUNT(susae.unadjusted) AS Total_Activty_Unadj,\n",
    "    COUNT(susae.adjusted) AS Total_Activty_Adj\n",
    " \n",
    "FROM eric.PAT_Intermediate_Table_AE_DB AS susae\n",
    " \n",
    "LEFT JOIN eric.Provider_Hierarchies_DB o \n",
    "    ON susae.Provider_Current = o.Organisation_Code  \n",
    " \n",
    "LEFT JOIN eric.Date_Full_DB AS d \n",
    "    ON d.Full_Date = susae.Attendance_Date\n",
    "\n",
    " WHERE\n",
    "    susae.Attendance_Date >= '2024-04-01'\n",
    "\n",
    "    AND susae.Provider_Current IN (\n",
    "        'RD1', 'RN3', 'RNZ', 'RA7', 'RVJ', 'REF', 'RA9', 'RH8',\n",
    "        'RK9', 'RBD', 'R0D', 'RTE', 'RH5'\n",
    "    )\n",
    "\n",
    "\n",
    "    AND susae.Pat_Commissioner_Type <> 'Private Patient'\n",
    " \n",
    "GROUP BY\n",
    "susae.Provider_Current,\n",
    "o.organisation_name,\n",
    "o.STP_Code,\n",
    "o.STP_Name,\n",
    "LEFT(susae.Dimention_7, 5),\n",
    "susae.Pat_Commissioner_Type,\n",
    "Attendance_Date,\n",
    "Dimention_1,\n",
    "susae.Attendance_Date;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c74f746f-c18d-4c2d-8069-45011687562a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Remove old files and folders  \n",
    "\n",
    "Before running the new files, delete the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a50e1fdb-489f-4302-bfdf-db7d73fdbbbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: JAR Activity - Productivity Output Files\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "import shutil\n",
    "import os\n",
    " \n",
    "local_path = r\"JAR Activity - Productivity Output Files\"\n",
    " \n",
    "# Check if the directory exists\n",
    "if os.path.exists(local_path):\n",
    "    shutil.rmtree(local_path)  # Deletes the entire directory\n",
    "    print(f\"Deleted: {local_path}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98839b45-b74f-41a6-9d5c-04a84fccb786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Create the Productivity Outputs  \n",
    "\n",
    "Using the views, generate files for each provider and system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb277710-9556-4465-9a71-d19eb3f4a1fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: JAR Activity - Productivity Output Files/UNIVERSITY_HOSPITALS_DORSET_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/UNIVERSITY_HOSPITALS_PLYMOUTH_NHS_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NORTH_BRISTOL_NHS_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/ROYAL_CORNWALL_HOSPITALS_NHS_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/ROYAL_UNITED_HOSPITALS_BATH_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/DORSET_COUNTY_HOSPITAL_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/GLOUCESTERSHIRE_HOSPITALS_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/GREAT_WESTERN_HOSPITALS_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/SOMERSET_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/ROYAL_DEVON_UNIVERSITY_HEALTHCARE_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/TORBAY_AND_SOUTH_DEVON_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/UNIVERSITY_HOSPITALS_BRISTOL_AND_WESTON_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/SALISBURY_NHS_FOUNDATION_TRUST_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NHS_DORSET_INTEGRATED_CARE_BOARD_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NHS_DEVON_INTEGRATED_CARE_BOARD_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NHS_BRISTOL,_NORTH_SOMERSET_AND_SOUTH_GLOUCESTERSHIRE_INTEGRATED_CARE_BOARD_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NHS_CORNWALL_AND_THE_ISLES_OF_SCILLY_INTEGRATED_CARE_BOARD_Jan-2025.xlsx\nSaved: JAR Activity - Productivity Output Files/NHS_BATH_AND_NORTH_EAST_SOMERSET,_SWINDON_AND_WILTSHIRE_INTEGRATED_CARE_BOARD_Jan-2025.xlsx\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:815)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:841)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:840)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:895)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:688)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:815)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:841)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:840)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:895)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:688)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    " \n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    " \n",
    "# Local OneDrive Path (Change if needed)\n",
    "local_path = r\"JAR Activity - Productivity Output Files\"\n",
    " \n",
    "# Ensure directory exists\n",
    "os.makedirs(local_path, exist_ok=True)\n",
    " \n",
    "# Read the SQL Views\n",
    "df_apc = spark.sql(\"SELECT * FROM PAT_APC\")\n",
    "df_op = spark.sql(\"SELECT * FROM PAT_OP\")\n",
    "df_ae = spark.sql(\"SELECT * FROM PAT_AE\")\n",
    " \n",
    "# Convert to Pandas\n",
    "df_apc_pandas = df_apc.toPandas()\n",
    "df_op_pandas = df_op.toPandas()\n",
    "df_ae_pandas = df_ae.toPandas()\n",
    " \n",
    "# Get the latest available date (MMM-YYYY format)\n",
    "latest_date = pd.to_datetime(df_apc_pandas[\"Discharge_Date\"]).max().strftime('%b-%Y')\n",
    " \n",
    "# Function to save DataFrame to an Excel file with multiple sheets\n",
    "def save_to_excel_with_tables(apc_df, op_df, ae_df, file_name):\n",
    "    file_path = os.path.join(local_path, file_name)\n",
    "    wb = Workbook()\n",
    "    # Remove the default sheet created by Workbook()\n",
    "    default_sheet = wb.active\n",
    "    wb.remove(default_sheet)\n",
    "    # Function to add DataFrame to a sheet with a table\n",
    "    def add_sheet_with_table(wb, df, sheet_name):\n",
    "        sheet = wb.create_sheet(title=sheet_name)\n",
    "        for row in dataframe_to_rows(df, index=False, header=True):\n",
    "            sheet.append(row)\n",
    "        table = Table(displayName=f\"{sheet_name}Table\", ref=f\"A1:{chr(64+df.shape[1])}{df.shape[0]+1}\")\n",
    "        style = TableStyleInfo(name=\"TableStyleMedium9\", showFirstColumn=False, showLastColumn=False, showRowStripes=True, showColumnStripes=True)\n",
    "        table.tableStyleInfo = style\n",
    "        sheet.add_table(table)\n",
    "    add_sheet_with_table(wb, apc_df, \"APC\")\n",
    "    add_sheet_with_table(wb, op_df, \"OP\")\n",
    "    add_sheet_with_table(wb, ae_df, \"AE\")\n",
    "    wb.save(file_path)\n",
    "    print(f\"Saved: {file_path}\")\n",
    " \n",
    "# Split and Save by Organisation Name\n",
    "for org in df_apc_pandas[\"organisation_name\"].unique():\n",
    "    org_apc_df = df_apc_pandas[df_apc_pandas[\"organisation_name\"] == org]\n",
    "    org_op_df = df_op_pandas[df_op_pandas[\"organisation_name\"] == org]\n",
    "    org_ae_df = df_ae_pandas[df_ae_pandas[\"organisation_name\"] == org]\n",
    "    org_clean = org.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    save_to_excel_with_tables(org_apc_df, org_op_df, org_ae_df, f\"{org_clean}_{latest_date}.xlsx\")\n",
    " \n",
    "# Split and Save by STP Name\n",
    "for stp in df_apc_pandas[\"STP_Name\"].unique():\n",
    "    stp_apc_df = df_apc_pandas[df_apc_pandas[\"STP_Name\"] == stp]\n",
    "    stp_op_df = df_op_pandas[df_op_pandas[\"STP_Name\"] == stp]\n",
    "    stp_ae_df = df_ae_pandas[df_ae_pandas[\"STP_Name\"] == stp]\n",
    "    stp_clean = stp.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    save_to_excel_with_tables(stp_apc_df, stp_op_df, stp_ae_df, f\"{stp_clean}_{latest_date}.xlsx\")\n",
    " \n",
    "print(\"‚úÖ Excel files successfully saved in JAR Activity - Productivity Output Files!\")\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4996883-416a-4190-a44b-92b20f006c86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Create Final Productivity Output File \n",
    "\n",
    "Using the views, generate SW totals file to QA highlevel to JAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5838d348-604e-4492-9276-2ae69ba0c1d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:815)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:841)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:840)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:895)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:688)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:138)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:815)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:841)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:840)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:895)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:688)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    " \n",
    "# Local OneDrive Path (Change if needed)\n",
    "local_path = r\"JAR Activity - Productivity Output Files\"\n",
    " \n",
    "# Ensure directory exists\n",
    "os.makedirs(local_path, exist_ok=True)\n",
    " \n",
    "# Read the SQL Views\n",
    "df_apc = spark.sql(\"SELECT * FROM PAT_APC\")\n",
    "df_op = spark.sql(\"SELECT * FROM PAT_OP\")\n",
    "df_ae = spark.sql(\"SELECT * FROM PAT_AE\")\n",
    " \n",
    "# Convert to Pandas\n",
    "df_apc_pandas = df_apc.toPandas()\n",
    "df_op_pandas = df_op.toPandas()\n",
    "df_ae_pandas = df_ae.toPandas()\n",
    " \n",
    "# Drop unnecessary fields\n",
    "drop_columns = [\"HRG\", \"TFC\", \"organisation_name\", \"STP_Name\", \"STP_Code\"]\n",
    "df_apc_pandas = df_apc_pandas.drop(columns=[col for col in drop_columns if col in df_apc_pandas.columns], errors='ignore')\n",
    "df_op_pandas = df_op_pandas.drop(columns=[col for col in drop_columns if col in df_op_pandas.columns], errors='ignore')\n",
    "df_ae_pandas = df_ae_pandas.drop(columns=[col for col in drop_columns if col in df_ae_pandas.columns], errors='ignore')\n",
    " \n",
    "# Aggregate total activity columns\n",
    "def aggregate_activity(df, group_by_cols):\n",
    "    sum_cols = [\"Total_Activty_Unadj\", \"Total_Activty_Adj\"]\n",
    "    return df.groupby(group_by_cols, as_index=False)[sum_cols].sum()\n",
    " \n",
    "# Define grouping columns including provider codes\n",
    "apc_group_by = [\"Der_Management_Type\", \"Provider_Code\"]\n",
    "ae_group_by = [\"Metric_ID\", \"Provider_Code\"]\n",
    "op_group_by = [\"High_Level_Pod\", \"Provider_Code\"]\n",
    " \n",
    "# Aggregate data\n",
    "df_apc_pandas = aggregate_activity(df_apc_pandas, apc_group_by)\n",
    "df_op_pandas = aggregate_activity(df_op_pandas, op_group_by)\n",
    "df_ae_pandas = aggregate_activity(df_ae_pandas, ae_group_by)\n",
    " \n",
    "# Get the latest available date (MMM-YYYY format)\n",
    "latest_date = pd.Timestamp.today().strftime('%b-%Y')\n",
    " \n",
    "# Function to save DataFrame to an Excel file with multiple sheets\n",
    "def save_to_excel_with_tables(apc_df, op_df, ae_df, file_name):\n",
    "    file_path = os.path.join(local_path, file_name)\n",
    "    wb = Workbook()\n",
    "    # Remove the default sheet created by Workbook()\n",
    "    default_sheet = wb.active\n",
    "    wb.remove(default_sheet)\n",
    "    # Function to add DataFrame to a sheet with a table\n",
    "    def add_sheet_with_table(wb, df, sheet_name):\n",
    "        sheet = wb.create_sheet(title=sheet_name)\n",
    "        for row in dataframe_to_rows(df, index=False, header=True):\n",
    "            sheet.append(row)\n",
    "        table = Table(displayName=f\"{sheet_name}Table\", ref=f\"A1:{chr(64+df.shape[1])}{df.shape[0]+1}\")\n",
    "        style = TableStyleInfo(name=\"TableStyleMedium9\", showFirstColumn=False, showLastColumn=False, showRowStripes=True, showColumnStripes=True)\n",
    "        table.tableStyleInfo = style\n",
    "        sheet.add_table(table)\n",
    "    add_sheet_with_table(wb, apc_df, \"APC\")\n",
    "    add_sheet_with_table(wb, op_df, \"OP\")\n",
    "    add_sheet_with_table(wb, ae_df, \"AE\")\n",
    "    wb.save(file_path)\n",
    "    print(f\"Saved: {file_path}\")\n",
    " \n",
    "# Save total data in a single file\n",
    "save_to_excel_with_tables(df_apc_pandas, df_op_pandas, df_ae_pandas, f\"Total_{latest_date}.xlsx\")\n",
    " \n",
    "print(\"‚úÖ Single Excel file with reduced size successfully saved in JAR Activity - Productivity Output Files!\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0aab5c-506b-4249-99dd-1ce37a486262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Contact\n",
    " \n",
    "To find out more about the South West Intelligence and Insights Team visit our [South West Intelligence and Insights Team Futures Page](https://future.nhs.uk/SouthWestAnalytics)) or get in touch at [england.southwestanalytics@nhs.net](mailto:england.southwestanalytics@nhs.net). Alternatively, Please feel free to reach out to me directly:\n",
    " \n",
    "üìß Email: [Destiny.Bradley@nhs.net](mailto:Destiny.Bradley@nhs.net)  \n",
    "üí¨ Teams: [Join my Teams](https://teams.microsoft.com/l/chat/0/0?users=<destiny.bradley@nhs.net)\n",
    " \n",
    "### Acknowledgements\n",
    "Thanks to Bernardo Detanico for his ongoing support in applying National Logic and Miles Filton for his support with getting started on Databricks"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "sql",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "JAR Activity - Productivity Outputs",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}